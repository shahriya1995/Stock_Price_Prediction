{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extra feature - 1) best N value 2) Keras Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import csv\n",
    "import numpy as np\n",
    "from scipy.stats import zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets,linear_model, preprocessing,utils\n",
    "from sklearn.metrics import mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "%matplotlib inline\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from keras.layers import Conv1D, Conv2D, MaxPooling2D \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Flatten ,Dropout\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.datasets import imdb\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from keras.layers import Bidirectional\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression chart.\n",
    "def chart_regression(pred,y,sort=True):\n",
    "    t = pd.DataFrame({'pred' : pred, 'y' : y.flatten()})\n",
    "    if sort:\n",
    "        t.sort_values(by=['y'],inplace=True)\n",
    "    a = plt.plot(t['y'].tolist(),label='expected')\n",
    "    b = plt.plot(t['pred'].tolist(),label='prediction')\n",
    "    plt.ylabel('output')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def to_sequences(seq_size,data,close):\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for i in range(len(data)-seq_size-1):\n",
    "        #print(i)\n",
    "        window = data[i:(i+seq_size)]\n",
    "        #print(window)\n",
    "        after_window = close[i+seq_size]\n",
    "        #print(after_window)\n",
    "        #after_window = after_window[4]\n",
    "        window = [[x] for x in window]\n",
    "        #print(\"{} - {}\".format(window,after_window))\n",
    "        x.append(window)\n",
    "        y.append(after_window)\n",
    "        \n",
    "    return np.array(x),np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Stock_Price.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_LSTM = pd.read_csv(\"CSC215_Project4_Stock_Price.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LSTM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_LSTM_new =df_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.156250</td>\n",
       "      <td>3.812500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>3675600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.015625</td>\n",
       "      <td>1077600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.031250</td>\n",
       "      <td>3.953125</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>437200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>3.843750</td>\n",
       "      <td>1883600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.734375</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>3.390625</td>\n",
       "      <td>7931600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open      High       Low     Close   Volume\n",
       "0  3.812500  4.156250  3.812500  4.125000  3675600\n",
       "1  4.125000  4.125000  4.000000  4.015625  1077600\n",
       "2  4.000000  4.031250  3.953125  4.000000   437200\n",
       "3  4.000000  4.000000  3.843750  3.843750  1883600\n",
       "4  3.734375  3.734375  3.390625  3.390625  7931600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LSTM_new=df_LSTM_new.drop(['Date', 'Adj_Close'], axis=1)\n",
    "df_LSTM_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4392, 5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_LSTM_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_close_lstm = df_LSTM_new['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "df_LSTM_new = scaler.fit_transform(df_LSTM_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3074\n",
      "1318\n"
     ]
    }
   ],
   "source": [
    "#x 70-30\n",
    "percent70 = int(len(df_LSTM_new)* 0.70)\n",
    "percent30 = len(df_LSTM_new) - percent70\n",
    "print(percent70)\n",
    "print(percent30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3074, 5)\n",
      "(1318, 5)\n"
     ]
    }
   ],
   "source": [
    "train = df_LSTM_new[0:percent70]\n",
    "test = df_LSTM_new[percent70:len(df_LSTM_new)]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3074,)\n",
      "(1318,)\n"
     ]
    }
   ],
   "source": [
    "train_close = df_close_lstm[0:percent70].values\n",
    "test_close =  df_close_lstm[percent70:len(df_close_lstm)].values\n",
    "print(train_close.shape)\n",
    "print(test_close.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_train: (3068, 5, 1, 5)\n",
      "Shape of x_test: (1312, 5, 1, 5)\n",
      "Shape of y_train: (3068,)\n",
      "Shape of y_test: (1312,)\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_SIZE = 5\n",
    "\n",
    "#print(x_train[0:2])\n",
    "#print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "x_train,y_train = to_sequences(SEQUENCE_SIZE,train,train_close)\n",
    "x_test,y_test = to_sequences(SEQUENCE_SIZE,test,test_close)\n",
    "\n",
    "print(\"Shape of x_train: {}\".format(x_train.shape))\n",
    "print(\"Shape of x_test: {}\".format(x_test.shape))\n",
    "print(\"Shape of y_train: {}\".format(y_train.shape))\n",
    "print(\"Shape of y_test: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train,(x_train.shape[0],x_train.shape[1],x_train.shape[3]))\n",
    "x_test = np.reshape(x_test,(x_test.shape[0],x_test.shape[1],x_test.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3068, 5, 5)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3068,)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer_lstm = ModelCheckpoint(filepath=\"./best_weights_lstm.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 198.2217 - val_loss: 3401.5812\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3401.58123, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 2/10\n",
      " - 1s - loss: 17.9698 - val_loss: 2490.8561\n",
      "\n",
      "Epoch 00002: val_loss improved from 3401.58123 to 2490.85609, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 3/10\n",
      " - 1s - loss: 11.2833 - val_loss: 2184.5674\n",
      "\n",
      "Epoch 00003: val_loss improved from 2490.85609 to 2184.56738, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.4186 - val_loss: 767.3777\n",
      "\n",
      "Epoch 00004: val_loss improved from 2184.56738 to 767.37766, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 5/10\n",
      " - 1s - loss: 5.3617 - val_loss: 554.2040\n",
      "\n",
      "Epoch 00005: val_loss improved from 767.37766 to 554.20402, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 6/10\n",
      " - 1s - loss: 4.3099 - val_loss: 236.9948\n",
      "\n",
      "Epoch 00006: val_loss improved from 554.20402 to 236.99481, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 7/10\n",
      " - 1s - loss: 3.5488 - val_loss: 116.4429\n",
      "\n",
      "Epoch 00007: val_loss improved from 236.99481 to 116.44293, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 8/10\n",
      " - 1s - loss: 3.1895 - val_loss: 52.4072\n",
      "\n",
      "Epoch 00008: val_loss improved from 116.44293 to 52.40718, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 9/10\n",
      " - 1s - loss: 3.0275 - val_loss: 20.5508\n",
      "\n",
      "Epoch 00009: val_loss improved from 52.40718 to 20.55076, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 10/10\n",
      " - 1s - loss: 2.5767 - val_loss: 59.9616\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 20.55076\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 188.1654 - val_loss: 1969.5998\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 20.55076\n",
      "Epoch 2/10\n",
      " - 1s - loss: 15.8244 - val_loss: 1094.1294\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 20.55076\n",
      "Epoch 3/10\n",
      " - 1s - loss: 11.9870 - val_loss: 646.6326\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 20.55076\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.7469 - val_loss: 319.2360\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 20.55076\n",
      "Epoch 5/10\n",
      " - 1s - loss: 5.5849 - val_loss: 38.2341\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 20.55076\n",
      "Epoch 6/10\n",
      " - 1s - loss: 4.4288 - val_loss: 26.2673\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 20.55076\n",
      "Epoch 7/10\n",
      " - 1s - loss: 3.7393 - val_loss: 53.6505\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 20.55076\n",
      "Epoch 8/10\n",
      " - 1s - loss: 3.6021 - val_loss: 29.1390\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 20.55076\n",
      "Epoch 9/10\n",
      " - 1s - loss: 2.7449 - val_loss: 33.6238\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 20.55076\n",
      "Epoch 10/10\n",
      " - 1s - loss: 3.3236 - val_loss: 30.2369\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 20.55076\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 208.8705 - val_loss: 3392.3702\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 20.55076\n",
      "Epoch 2/10\n",
      " - 1s - loss: 15.6962 - val_loss: 1196.9473\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 20.55076\n",
      "Epoch 3/10\n",
      " - 1s - loss: 13.5735 - val_loss: 338.6948\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 20.55076\n",
      "Epoch 4/10\n",
      " - 1s - loss: 8.9637 - val_loss: 356.3326\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 20.55076\n",
      "Epoch 5/10\n",
      " - 1s - loss: 6.8000 - val_loss: 254.8711\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 20.55076\n",
      "Epoch 6/10\n",
      " - 1s - loss: 5.9518 - val_loss: 36.1494\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 20.55076\n",
      "Epoch 7/10\n",
      " - 1s - loss: 4.2961 - val_loss: 31.0555\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 20.55076\n",
      "Epoch 8/10\n",
      " - 1s - loss: 3.8533 - val_loss: 28.3664\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 20.55076\n",
      "Epoch 9/10\n",
      " - 1s - loss: 3.5706 - val_loss: 16.1360\n",
      "\n",
      "Epoch 00009: val_loss improved from 20.55076 to 16.13596, saving model to ./best_weights_lstm.hdf5\n",
      "Epoch 10/10\n",
      " - 1s - loss: 2.9850 - val_loss: 21.0705\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 204.2087 - val_loss: 3739.3452\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.13596\n",
      "Epoch 2/10\n",
      " - 1s - loss: 15.2936 - val_loss: 1370.7860\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.13596\n",
      "Epoch 3/10\n",
      " - 1s - loss: 11.7689 - val_loss: 1435.2729\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.13596\n",
      "Epoch 4/10\n",
      " - 1s - loss: 7.6668 - val_loss: 335.2121\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 16.13596\n",
      "Epoch 5/10\n",
      " - 1s - loss: 5.6578 - val_loss: 42.9173\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 16.13596\n",
      "Epoch 6/10\n",
      " - 1s - loss: 4.7368 - val_loss: 32.0835\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 16.13596\n",
      "Epoch 7/10\n",
      " - 1s - loss: 3.6032 - val_loss: 20.8163\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 16.13596\n",
      "Epoch 8/10\n",
      " - 1s - loss: 3.8224 - val_loss: 22.0529\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.13596\n",
      "Epoch 9/10\n",
      " - 1s - loss: 3.1876 - val_loss: 136.9694\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.13596\n",
      "Epoch 10/10\n",
      " - 1s - loss: 3.2405 - val_loss: 77.5660\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 4s - loss: 176.9841 - val_loss: 4811.4799\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.13596\n",
      "Epoch 2/10\n",
      " - 1s - loss: 17.9479 - val_loss: 3686.2735\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.13596\n",
      "Epoch 3/10\n",
      " - 1s - loss: 13.5537 - val_loss: 3337.2227\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.13596\n",
      "Epoch 4/10\n",
      " - 1s - loss: 8.5990 - val_loss: 1841.0698\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 16.13596\n",
      "Epoch 5/10\n",
      " - 1s - loss: 6.5089 - val_loss: 1254.8404\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 16.13596\n",
      "Epoch 6/10\n",
      " - 1s - loss: 5.6730 - val_loss: 1095.4594\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 16.13596\n",
      "Epoch 7/10\n",
      " - 1s - loss: 5.2467 - val_loss: 766.1000\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 16.13596\n",
      "Epoch 8/10\n",
      " - 1s - loss: 4.0844 - val_loss: 379.1631\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.13596\n",
      "Epoch 9/10\n",
      " - 1s - loss: 3.1849 - val_loss: 213.1859\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.13596\n",
      "Epoch 10/10\n",
      " - 1s - loss: 2.7238 - val_loss: 102.7768\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)\n",
    "    \n",
    "    print('Build model...')\n",
    "    model_lstm = Sequential()\n",
    "\n",
    "    model_lstm.add(LSTM(64, dropout=0.1, recurrent_dropout=0.1, input_shape=(5, 5),activation=\"relu\"))\n",
    "    model_lstm.add(Dense(32, activation=\"relu\"))\n",
    "    model_lstm.add(Dense(1))\n",
    "    model_lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "    model_lstm.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer_lstm],verbose=2, epochs=10)  \n",
    "\n",
    " \n",
    "print()\n",
    "model_lstm.load_weights('./best_weights_lstm.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 4.016958408779251\n"
     ]
    }
   ],
   "source": [
    "pred = model_lstm.predict(x_test)\n",
    "score = np.sqrt(metrics.mean_squared_error(pred,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14522cda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chart_regression(pred.flatten(),y_test,sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802344976934115\n"
     ]
    }
   ],
   "source": [
    "score_r2 = r2_score(pred,y_test)\n",
    "print(format(score_r2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras layer wrappers to create an even more complicated layer feature 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer_lstm_n = ModelCheckpoint(filepath=\"./best_weights_lstm_n.hdf5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 7s - loss: 238.6084 - val_loss: 3453.1013\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.13596\n",
      "Epoch 2/10\n",
      " - 1s - loss: 55.2726 - val_loss: 2294.6122\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.13596\n",
      "Epoch 3/10\n",
      " - 1s - loss: 7.8354 - val_loss: 1706.3890\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.13596\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.7197 - val_loss: 1487.4828\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 16.13596\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.7564 - val_loss: 1388.7534\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 16.13596\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.5107 - val_loss: 1335.1389\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 16.13596\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.3964 - val_loss: 1303.8836\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 16.13596\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3704 - val_loss: 1283.6497\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.13596\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.3514 - val_loss: 1273.7339\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.13596\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3603 - val_loss: 1263.7982\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "1\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 236.2483 - val_loss: 3233.2707\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.13596\n",
      "Epoch 2/10\n",
      " - 1s - loss: 44.5521 - val_loss: 2122.7677\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.13596\n",
      "Epoch 3/10\n",
      " - 1s - loss: 5.1230 - val_loss: 1625.6931\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.13596\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.3160 - val_loss: 1449.9797\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 16.13596\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.7417 - val_loss: 1374.8856\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 16.13596\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.5438 - val_loss: 1329.1086\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 16.13596\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.4398 - val_loss: 1295.9943\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 16.13596\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3840 - val_loss: 1271.9664\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.13596\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.3494 - val_loss: 1254.9796\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.13596\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3524 - val_loss: 1243.1105\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "2\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 254.1487 - val_loss: 3625.9824\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.13596\n",
      "Epoch 2/10\n",
      " - 1s - loss: 62.7001 - val_loss: 2354.5729\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.13596\n",
      "Epoch 3/10\n",
      " - 1s - loss: 8.5990 - val_loss: 1706.1428\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.13596\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.7222 - val_loss: 1484.1579\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 16.13596\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.7410 - val_loss: 1389.9844\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 16.13596\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.4975 - val_loss: 1337.1078\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 16.13596\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.3994 - val_loss: 1304.3418\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 16.13596\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3681 - val_loss: 1282.1242\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.13596\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.3548 - val_loss: 1269.6376\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.13596\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3508 - val_loss: 1260.5126\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "3\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 241.1031 - val_loss: 3416.8730\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.13596\n",
      "Epoch 2/10\n",
      " - 1s - loss: 52.3311 - val_loss: 2191.9310\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.13596\n",
      "Epoch 3/10\n",
      " - 1s - loss: 6.0109 - val_loss: 1638.8449\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.13596\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.3581 - val_loss: 1455.4028\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 16.13596\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.7182 - val_loss: 1373.0192\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 16.13596\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.5146 - val_loss: 1326.2559\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 16.13596\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.4255 - val_loss: 1293.4490\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 16.13596\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3836 - val_loss: 1272.7229\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.13596\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.3810 - val_loss: 1259.9351\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.13596\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3525 - val_loss: 1249.8830\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "4\n",
      "Build model...\n",
      "Train...\n",
      "Train on 3068 samples, validate on 1312 samples\n",
      "Epoch 1/10\n",
      " - 8s - loss: 252.1542 - val_loss: 3532.1907\n",
      "\n",
      "Epoch 00001: val_loss did not improve from 16.13596\n",
      "Epoch 2/10\n",
      " - 1s - loss: 62.7152 - val_loss: 2353.1965\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 16.13596\n",
      "Epoch 3/10\n",
      " - 1s - loss: 8.1974 - val_loss: 1693.5731\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 16.13596\n",
      "Epoch 4/10\n",
      " - 1s - loss: 1.5996 - val_loss: 1480.4776\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 16.13596\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.7572 - val_loss: 1387.8092\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 16.13596\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.5105 - val_loss: 1335.9349\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 16.13596\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.4113 - val_loss: 1301.6432\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 16.13596\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.3643 - val_loss: 1282.0779\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 16.13596\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.3562 - val_loss: 1268.6958\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 16.13596\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.3501 - val_loss: 1259.6976\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 16.13596\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (Unable to open file: name = './best_weights_lstm_n.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-99ba540feb65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmodel_lstm_n\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./best_weights_lstm_n.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1157\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1158\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1159\u001b[0m                 \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (Unable to open file: name = './best_weights_lstm_n.hdf5', errno = 2, error message = 'no such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i)\n",
    "    \n",
    "    print('Build model...')\n",
    "    model_lstm_n = Sequential()\n",
    "\n",
    "    model_lstm_n.add(Bidirectional(LSTM(20, return_sequences=True),input_shape=(5,5)))\n",
    "    model_lstm_n.add(Bidirectional(LSTM(10)))\n",
    "    model_lstm_n.add(Dense(32, activation=\"relu\"))\n",
    "    model_lstm_n.add(Dense(1))\n",
    "    model_lstm_n.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    monitor = EarlyStopping(monitor='val_loss', min_delta=1e-3, patience=5, verbose=1, mode='auto')\n",
    "    print('Train...')\n",
    "    model_lstm_n.fit(x_train,y_train,validation_data=(x_test,y_test),callbacks=[monitor,checkpointer_lstm],verbose=2, epochs=10)  \n",
    "\n",
    " \n",
    "print()\n",
    "model_lstm_n.load_weights('./best_weights_lstm_n.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (RMSE): 4.016958408779251\n"
     ]
    }
   ],
   "source": [
    "pred_m = model_lstm.predict(x_test)\n",
    "score_m = np.sqrt(metrics.mean_squared_error(pred_m,y_test))\n",
    "print(\"Score (RMSE): {}\".format(score_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9802344976934115\n"
     ]
    }
   ],
   "source": [
    "score_r2_m = r2_score(pred_m,y_test)\n",
    "print(format(score_r2_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
